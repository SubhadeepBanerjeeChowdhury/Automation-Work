def update_family_value(df, ind_col, family_col):
    for i, row in df.iterrows():
        if row[ind_col].isdigit() and row[family_col] == '':
            df.at[i, family_col] = str(int(row[ind_col]) * 2)

# List of column pairs to apply the logic to
column_pairs = [
    ('IND DEDUCTIBLE INN', 'FAMILY DEDUCTIBLE INN'),
    ('IND DEDUCTIBLE OON', 'FAMILY DEDUCTIBLE OON'),
    ('IND OOP INN', 'FAMILY OOP INN'),
    ('IND OOP OON', 'FAMILY OOP OON')
]

# Apply the function to each column pair
for ind_col, family_col in column_pairs:
    update_family_value(oxford_final, ind_col, family_col)


*********************************
import cv2

# Load the image
image = cv2.imread(r"C:\Users\Subhadeep\Downloads\Book-2.png")

# Convert the image to grayscale
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Apply a threshold to get a binary image
_, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

# Find contours of the text regions
contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# Initialize variables to store the rightmost and bottommost coordinates
rightmost = 0
bottommost = 0

# Loop through all contours to find the rightmost and bottommost coordinates
for contour in contours:
    x, y, w, h = cv2.boundingRect(contour)
    rightmost = max(rightmost, x + w)
    bottommost = max(bottommost, y + h)

# Add a buffer to the bounding box
buffer = 10
x = rightmost + buffer
y = bottommost + buffer


# Crop the image using the calculated bounding box
cropped_image = image[:y, :x]


import matplotlib.pyplot as plt
plt.imshow(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))
plt.axis('off')  # Turn off axis
plt.show()



from openpyxl import load_workbook
from openpyxl.styles import PatternFill

def highlight_cells(df, file_path):
    # Save DataFrame to an Excel file
    df.to_excel(file_path, index=False)

    # Load the workbook and select the active worksheet
    wb = load_workbook(file_path)
    ws = wb.active

    # Define the fill for yellow and red colors
    yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
    red_fill = PatternFill(start_color="FF0000", end_color="FF0000", fill_type="solid")

    # Iterate over the rows and apply conditional formatting
    for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=1, max_col=ws.max_column):
        highlight_row = None  # No highlight by default
        for cell in row:
            if 'NOT' in str(cell.value):
                highlight_row = yellow_fill
                break  # No need to check further cells in this row
            if 'OMITTED' in str(cell.value):
                highlight_row = red_fill
                break  # No need to check further cells in this row
        if highlight_row:
            for cell in row:
                cell.fill = highlight_row

    # Save the workbook with the formatting
    wb.save(file_path)

# Sample DataFrame
data = {
    'Column1': ['Value1', 'NOT', 'Value3', 'OMITTED'],
    'Column2': ['Value2', 'Value4', 'NOT', 'Value5'],
    'Column3': ['OMITTED', 'Value6', 'Value7', 'Value8']
}

df = pd.DataFrame(data)
file_path = r'C:\Users\Subhadeep\Downloads\highlighted_rows.xlsx'

# Execute the highlight_cells function on the DataFrame
highlight_cells(df, file_path)


-----------------------------------------------------------------------------------------------------

import os
import glob

def find_latest_file(base_path, folder_keywords, file_keywords):
    # Get the list of folders
    folders = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f)) and any(keyword in f for keyword in folder_keywords)]
    
    if folders:
        # Sort folders by year in descending order
        folders.sort(reverse=True)
        
        # Iterate over the folders starting from the latest
        for folder in folders:
            folder_path = os.path.join(base_path, folder)
            
            # Find the latest file matching the keywords
            search_pattern = os.path.join(folder_path, '*.xlsx')
            files = [f for f in glob.glob(search_pattern) if all(keyword in os.path.basename(f) for keyword in file_keywords)]
            
            if files:
                # Sort files by modified date in descending order and return the latest one
                latest_file = max(files, key=os.path.getmtime)
                return latest_file
    else:
        # If no folders found, search in the base path directly
        search_pattern = os.path.join(base_path, '*.xlsx')
        files = [f for f in glob.glob(search_pattern) if all(keyword in os.path.basename(f) for keyword in file_keywords)]
        
        if files:
            # Sort files by modified date in descending order and return the latest one
            latest_file = max(files, key=os.path.getmtime)
            return latest_file

    return None


base_path_adp = r'C:\Users\Subhadeep\Downloads\Configuration Team MNS plans\ADP'
base_path_prestige = r'C:\Users\Subhadeep\Downloads\Configuration Team MNS plans\Prestige'
base_sot_folder=r"C:\Users\Subhadeep\Downloads\SOT"
folder_keywords = [str(year) for year in range(2023, 2035)]
file_keywords_adp = ['ADP', 'Portfolio']
file_keywords_prestige = ['Prestige', 'Portfolio']
file_keywords_ny=['NY','MNS','BARTrack']
file_keywords_nj=['NJ','MNS','BARTrack']
file_keywords_ct=['CT','MNS','BARTrack']


adp_path = find_latest_file(base_path_adp, folder_keywords, file_keywords_adp)
prestige_path = find_latest_file(base_path_prestige, folder_keywords, file_keywords_prestige)
ox_ny_path=find_latest_file(base_sot_folder, folder_keywords, file_keywords_ny)
ox_nj_path=find_latest_file(base_sot_folder, folder_keywords, file_keywords_nj)
ox_ct_path=find_latest_file(base_sot_folder, folder_keywords, file_keywords_ct)

print(adp_path)
print(prestige_path)
print(ox_ny_path)
print(ox_ct_path)
print(ox_nj_path)



**************************************************************************************


# Function to set ID Card Template based on conditions
def set_id_card_template(row):
    try:
        if 'NJ' in row['TRACKING ID'] or 'NJ' in row['sheetname'] or 'NJ' in row['filename']:
            if row['FUNDING TYPE'] == 'Fully Insured':
                return 'OXFN4'
        if 'NY' in row['TRACKING ID'] or 'NY' in row['sheetname'] or 'NY' in row['filename']:
            if row['FUNDING TYPE'] == 'Fully Insured':
                if all(x in [0, '0', ''] for x in [row['PCP TIER COPAY'], row['SPEC TIER COPAY']]):
                    return 'UHC02'
                elif all(x not in [0, '0', ''] for x in [row['PCP TIER COPAY'], row['SPEC TIER COPAY']]):
                    return 'UHC01'
        if 'CT' in row['TRACKING ID'] or 'CT' in row['sheetname'] or 'CT' in row['filename']:
            if 'Ded' in row['PCP COPAY'] or 'Ded' in row['SPEC COPAY']:
                return 'OXFN5'
            try:
                if (int(row['PCP COPAY']) > 0) or (int(row['SPEC COPAY']) > 0):
                    return 'OXFN1'
            except ValueError:
                pass
    except Exception as e:
        print(f"Error processing row: {e}")
    return ''

# Apply the function to the DataFrame
tkinter_df['ID Card Template'] = tkinter_df.apply(set_id_card_template, axis=1)



################################################################################################################################

#Predefined inputs

bob = 'UHC FREEDOM'
date = '07/01/2023'
#List of MNS plans that are extracted
mnstuple=('MNS0400016','MNS0400017','MNS0400013','MNS0400014','MNS0400009','MNS0400010')

folder_date = date.replace('/', '_')
cwd = os.getcwd()
bob_folder = os.path.join(cwd, "Output", folder_date, bob)

# List to store the sheet names
output_sheets = []

# Check if the date folder exists
if os.path.exists(os.path.join(cwd, "Output", folder_date)):
    # Check if the BoB folder exists inside the date folder
    if os.path.exists(bob_folder):
        # Iterate over all files in the BoB folder
        for file_name in os.listdir(bob_folder):
            if file_name.endswith(".xlsx") or file_name.endswith(".xls"):
                file_path = os.path.join(bob_folder, file_name)
                xls = pd.ExcelFile(file_path)
                for i in xls.sheet_names:
                    output_sheets.append(i)
audit_dict = {mns_id: 'Audited' if any(mns_id in sheet for sheet in output_sheets) else 'Not Audited' for mns_id in mnstuple}
audit_dict

*******************************************************************************************************************************************************


import os
import pandas as pd
data={'MNS ID':['MNS0400013','MNS0400013','MNS0400016','MNS0400016','MNS0400009','MNS0400010','MNS0400000'],'GROUP NAME':['RAFTERONE','RAFTERONE','HOME HOSPICE','HOME HOSPICE','HOME HOSPICE','AIR GENERAL','AIR GENERAL'],'Option':['1','2','1','2','1','1','1']}
tufts_df=pd.DataFrame(data)
#Predefined inputs

bob = 'UHC FREEDOM'
date = '07/01/2023'


def get_audit_status(row):
    folder_date = date.replace('/', '_')
    cwd = os.getcwd()
    bob_folder = os.path.join(cwd, "Output", folder_date, bob)

    # List to store the sheet names
    output_sheets = []

    # Check if the date folder exists
    if os.path.exists(os.path.join(cwd, "Output", folder_date)):
        # Check if the BoB folder exists inside the date folder
        if os.path.exists(bob_folder):
            # Iterate over all files in the BoB folder
            for file_name in os.listdir(bob_folder):
                if file_name.endswith(".xlsx") or file_name.endswith(".xls"):
                    file_path = os.path.join(bob_folder, file_name)
                    xls = pd.ExcelFile(file_path)
                    for i in xls.sheet_names:
                        output_sheets.append(i)
    if row['Option']:
        if str(row['MNS ID']+'_'+row['Option']) in str(output_sheets):
            return 'Audited'
        else:
            return 'Not Audited'
    else:
        if row['MNS ID'] in str(output_sheets):
            return 'Audited'
        else:
            return 'Not Audited'
    
tufts_df['Audit Status']=tufts_df.apply(get_audit_status,axis=1)
if 'Audited' in str(tufts_df['Audit Status'].to_list()):
    message_2='You have already audited '+ str(len(tufts_df[tufts_df['Audit Status']=='Audited']['MNS ID'].to_list()))+' out of '+str(len(tufts_df['MNS ID'].to_list()))+ ' plans.\nDo you want to restart the audit or skip the audited plans?'
    print(message_2)
    user_input=str(input('Restart/Skip?:'))
    if user_input=='Skip':
        filtered_df=tufts_df[tufts_df['Audit Status']=='Not Audited']
        print(filtered_df)
    else:
        print(tufts_df)


import os

def find_files_with_keywords(folder_path, keyword_list):
    """
    Finds files in the given folder where the filenames contain all the keywords.
    
    Parameters:
    folder_path (str): The path to the folder to search.
    keyword_list (list): A list of keywords to look for in the filenames.
    
    Returns:
    list: A list of file paths that match the criteria.
    """
    matching_files = []
    
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if all(keyword in file for keyword in keyword_list):
                matching_files.append(os.path.join(root, file))
    
    return matching_files

# Example usage
folder_path = '/path/to/your/folder'
keyword_list = ['keyword1', 'keyword2']

matching_files = find_files_with_keywords(folder_path, keyword_list)
for file_path in matching_files:
    print(file_path)



def move_to_archive(origin, destination, omit_list):
    """
    Moves all files and folders from the origin to the destination,
    excluding the file/folder paths in the omit_list.
    
    Parameters:
    origin (str): The path to the origin folder.
    destination (str): The path to the destination folder.
    omit_list (list): A list of file/folder paths to omit from moving.
    """
    # Ensure the destination directory exists
    os.makedirs(destination, exist_ok=True)

    # Normalize the omit_list paths
    omit_list = [os.path.normpath(path) for path in omit_list]

    # Iterate over all files and directories in the origin directory
    for root, dirs, files in os.walk(origin, topdown=False):
        for name in files + dirs:
            # Construct the full path
            full_path = os.path.join(root, name)
            
            # Check if the full path is not in the omit list
            if full_path not in omit_list:
                # Construct the destination path
                relative_path = os.path.relpath(full_path, origin)
                dest_path = os.path.join(destination, relative_path)
                
                # Ensure the destination directory exists
                os.makedirs(os.path.dirname(dest_path), exist_ok=True)

                # Move the file or directory
                shutil.move(full_path, dest_path)
                print(f"Moved: {full_path} to {dest_path}")





def move_to_archive(origin, destination, omit_list):
    """
    Moves all files and folders from the origin to the destination,
    excluding the file/folder paths in the omit_list.
    
    Parameters:
    origin (str): The path to the origin folder.
    destination (str): The path to the destination folder.
    omit_list (list): A list of file/folder paths to omit from moving.
    """
    # Ensure the destination directory exists
    os.makedirs(destination, exist_ok=True)

    # Normalize the omit_list paths
    omit_list = [os.path.normpath(path) for path in omit_list]

    # Iterate over all files and directories in the origin directory
    for root, dirs, files in os.walk(origin, topdown=True):
        # Skip directories in omit_list
        dirs[:] = [d for d in dirs if os.path.normpath(os.path.join(root, d)) not in omit_list]

        for name in files + dirs:
            # Construct the full path
            full_path = os.path.join(root, name)
            
            # Check if the full path is not in the omit list
            if full_path not in omit_list:
                # Construct the destination path
                relative_path = os.path.relpath(full_path, origin)
                dest_path = os.path.join(destination, relative_path)
                
                # Ensure the destination directory exists
                os.makedirs(os.path.dirname(dest_path), exist_ok=True)

                # Move the file or directory
                if os.path.exists(dest_path):
                    if os.path.isdir(dest_path):
                        shutil.rmtree(dest_path)
                    else:
                        os.remove(dest_path)

                shutil.move(full_path, dest_path)
                print(f"Moved: {full_path} to {dest_path}")





def check_date_format(date):
    # Regular expression to match mm/dd/yyyy format
    pattern = re.compile(r'^(0[1-9]|1[0-2])/([0-2][0-9]|3[01])/\d{4}$')
    return bool(pattern.match(date))


def get_sheetnames_from_folder(folder_path):
    sheetnames = []
    for root, _, files in os.walk(folder_path):
        for file in files:
            if file.endswith('.xlsx'):
                file_path = os.path.join(root, file)
                workbook = load_workbook(file_path, read_only=True)
                sheetnames.extend(workbook.sheetnames)
                workbook.close()
    return sheetnames

def remove_duplicate_sheets(discard_folder, output_folder):
    discard_sheets = get_sheetnames_from_folder(discard_folder)
    output_sheets = get_sheetnames_from_folder(output_folder)

    for root, _, files in os.walk(output_folder):
        for file in files:
            if file.endswith('.xlsx'):
                file_path = os.path.join(root, file)
                workbook = load_workbook(file_path)
                for sheetname in workbook.sheetnames:
                    if sheetname in discard_sheets:
                        del workbook[sheetname]
                workbook.save(file_path)
                workbook.close()
    
    return discard_sheets, output_sheets

# Example usage:
discard_folder =r"C:\Users\Subhadeep\Downloads\UHC Project\Output\Discarded Plans"
output_folder = r"C:\Users\Subhadeep\Downloads\UHC Project\Output\07_01_2023"

discard_sheets, output_sheets = remove_duplicate_sheets(discard_folder, output_folder)

def delete_all_files(folder_path):
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            file_path = os.path.join(root, file)
            try:
                os.remove(file_path)
                print(f"Deleted file: {file_path}")
            except Exception as e:
                print(f"Error deleting file {file_path}: {e}")
        for dir in dirs:
            dir_path = os.path.join(root, dir)
            try:
                shutil.rmtree(dir_path)
                print(f"Deleted directory and its contents: {dir_path}")
            except Exception as e:
                print(f"Error deleting directory {dir_path}: {e}")



import requests
from requests_ntlm import HttpNtlmAuth
import os

# SharePoint URL where the files are located
SHAREPOINT_URL = 'https://your-sharepoint-site.com/sites/your-site/Shared%20Documents/'

# Your SharePoint username and password
USERNAME = 'your_username'
PASSWORD = 'your_password'

# Local directory path to save the downloaded files
LOCAL_PATH_TO_SAVE = '/path/to/local/directory/'

# Function to authenticate and retrieve file list
def download_sharepoint_files(url, username, password, local_path):
    # Construct the endpoint to get file metadata (adjust based on your SharePoint setup)
    endpoint_url = url + "_api/web/lists/getbytitle('Documents')/items?$select=FileLeafRef"

    try:
        # Send GET request to SharePoint API with NTLM authentication
        response = requests.get(endpoint_url, auth=HttpNtlmAuth(username, password))

        # Check if request was successful
        if response.status_code == 200:
            files_data = response.json()

            # Iterate through each file metadata
            for item in files_data['value']:
                file_name = item['FileLeafRef']
                file_url = url + file_name

                # Download each file
                download_file(file_url, username, password, local_path)

            print("All files downloaded successfully.")
        else:
            print(f"Failed to retrieve file list. Status code: {response.status_code}")

    except requests.exceptions.RequestException as e:
        print(f"Error: {e}")

# Function to download a file
def download_file(file_url, username, password, local_path):
    try:
        # Send GET request to download file with NTLM authentication
        response = requests.get(file_url, auth=HttpNtlmAuth(username, password), stream=True)

        # Check if request was successful
        if response.status_code == 200:
            # Extract filename from URL
            file_name = os.path.basename(file_url)

            # Save file to local directory
            with open(os.path.join(local_path, file_name), 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)

            print(f"File '{file_name}' downloaded successfully.")
        else:
            print(f"Failed to download file '{file_url}'. Status code: {response.status_code}")

    except requests.exceptions.RequestException as e:
        print(f"Error downloading file '{file_url}': {e}")

# Call the function to start downloading files
download_sharepoint_files(SHAREPOINT_URL, USERNAME, PASSWORD, LOCAL_PATH_TO_SAVE)


import requests
import os
from requests.auth import HTTPBasicAuth  # Assuming basic authentication

# SharePoint URL where the files are located
SHAREPOINT_URL = 'https://your-sharepoint-site.com/sites/your-site/Shared%20Documents/Your%20Library/'

# Your SharePoint username and password
USERNAME = 'your_username'
PASSWORD = 'your_password'

# Local directory path to save the downloaded files
LOCAL_PATH_TO_SAVE = '/path/to/local/directory/'

# Function to download files from SharePoint
def download_sharepoint_files(url, username, password, local_path):
    try:
        # Send GET request to SharePoint with basic authentication
        response = requests.get(url, auth=HTTPBasicAuth(username, password), stream=True)

        # Check if request was successful
        if response.status_code == 200:
            # Iterate through each file in the directory
            for file_name in response.json()['value']:
                # Construct the full URL of each file
                file_url = os.path.join(url, file_name['Name'])

                # Download each file
                download_file(file_url, username, password, local_path)

            print("All files downloaded successfully.")
        else:
            print(f"Failed to retrieve file list. Status code: {response.status_code}")

    except requests.exceptions.RequestException as e:
        print(f"Error: {e}")

# Function to download a file
def download_file(file_url, username, password, local_path):
    try:
        # Send GET request to download file with basic authentication
        response = requests.get(file_url, auth=HTTPBasicAuth(username, password), stream=True)

        # Check if request was successful
        if response.status_code == 200:
            # Extract filename from URL
            file_name = os.path.basename(file_url)

            # Save file to local directory
            with open(os.path.join(local_path, file_name), 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)

            print(f"File '{file_name}' downloaded successfully.")
        else:
            print(f"Failed to download file '{file_url}'. Status code: {response.status_code}")

    except requests.exceptions.RequestException as e:
        print(f"Error downloading file '{file_url}': {e}")

# Call the function to start downloading files
download_sharepoint_files(SHAREPOINT_URL, USERNAME, PASSWORD, LOCAL_PATH_TO_SAVE)



from sharepy import connect

# SharePoint URL where the file is located
SHAREPOINT_URL = 'https://your-sharepoint-site.com/sites/your-site/'

# Your SharePoint username and password
USERNAME = 'your_username'
PASSWORD = 'your_password'

# Local directory path to save the downloaded file
LOCAL_PATH_TO_SAVE = '/path/to/local/directory/'

# Function to download a file from SharePoint
def download_sharepoint_file(url, username, password, local_path):
    try:
        # Connect to SharePoint
        s = connect(url, username, password)

        # Download file
        response = s.getfile(url, filename=os.path.join(local_path, os.path.basename(url)))

        if response.status_code == 200:
            print(f"File '{os.path.basename(url)}' downloaded successfully.")
        else:
            print(f"Failed to download file '{url}'. Status code: {response.status_code}")

    except Exception as e:
        print(f"Error downloading file '{url}': {e}")

# Construct the full URL of the file to download
file_url = 'https://your-sharepoint-site.com/sites/your-site/Shared%20Documents/Your%20Library/example.xlsx'

# Call the function to download the file
download_sharepoint_file(file_url, USERNAME, PASSWORD, LOCAL_PATH_TO_SAVE)

